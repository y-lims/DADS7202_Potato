{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGS/9EH0CYI6flF82sOmyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y-lims/DADS7202_Potato/blob/main/Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow_similarity matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VEeDK4ncQmI",
        "outputId": "7cf1b1ed-b488-4cd1-c3c1-8ca0bd58050f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting tensorflow_similarity\n",
            "  Downloading tensorflow_similarity-0.17.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Collecting distinctipy (from tensorflow_similarity)\n",
            "  Downloading distinctipy-1.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting nmslib (from tensorflow_similarity)\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (2.1.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=4.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (4.9.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (4.66.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (3.4.3)\n",
            "Collecting umap-learn (from tensorflow_similarity)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (4.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (14.0.2)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets>=4.2->tensorflow_similarity) (1.7.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (3.1.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (6.0.1)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (2024.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_similarity) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_similarity) (2024.1)\n",
            "Collecting pybind11<2.6.2 (from nmslib->tensorflow_similarity)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (1.3.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->tensorflow_similarity)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets>=4.2->tensorflow_similarity) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets>=4.2->tensorflow_similarity) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets>=4.2->tensorflow_similarity) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->tensorflow_similarity) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->tensorflow_similarity) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn->tensorflow_similarity) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn->tensorflow_similarity) (3.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: docstring-parser~=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets>=4.2->tensorflow_similarity) (0.16)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow_similarity-0.17.1-py3-none-any.whl (230 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.4/230.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distinctipy-1.3.4-py3-none-any.whl (26 kB)\n",
            "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nmslib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47d1DdypbJX4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print( f\"Python {sys.version}\\n\" )\n",
        "\n",
        "import numpy as np\n",
        "print( f\"NumPy {np.__version__}\\n\" )\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print( f\"Matplotlib {matplotlib.__version__}\\n\" )\n",
        "\n",
        "import tensorflow as tf\n",
        "print( f\"TensorFlow {tf.__version__}\" )\n",
        "print( f\"tf.keras.backend.image_data_format() = {tf.keras.backend.image_data_format()}\" )\n",
        "\n",
        "# Count the number of GPUs as detected by tensorflow\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print( f\"TensorFlow detected { len(gpus) } GPU(s):\" )\n",
        "for i, gpu in enumerate(gpus):\n",
        "  print( f\".... GPU No. {i}: Name = {gpu.name} , Type = {gpu.device_type}\" )\n",
        "\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.cm as cmp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set fixed seeding values for reproducability during experiments\n",
        "# Skip this cell if random initialization (with varied results) is needed\n",
        "np_random_seed = 1\n",
        "tf_random_seed = 1\n",
        "model_name = 'vgg16'\n",
        "version = 'v4'\n",
        "seedno = 1\n",
        "owner_name = 'l_model'\n",
        "\n",
        "\n",
        "# Define a flag to check if running on Colab\n",
        "on_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "np.random.seed(np_random_seed)\n",
        "tf.random.set_seed(tf_random_seed)"
      ],
      "metadata": {
        "id": "6aPsv46RbPqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if on_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_path = '/content/drive/My Drive/Final_Potato'\n",
        "else:\n",
        "    base_path = 'D:/anaconda3/envs/tfv1/00_deep_prj/Final_Potato'\n",
        "\n"
      ],
      "metadata": {
        "id": "dQA1fAOybRe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "allowed_extensions = (\".JPG\", \".jpg\", \".jpeg\", \".JPEG\", \".PNG\", \".png\")\n",
        "class_mapping = {'Healthy': 0, 'Blackleg': 1, 'Black Scurf': 2, 'Pink Rot': 3, 'Common Scab': 4, 'Dry Rot': 5}\n",
        "\n",
        "def process_dataset_with_split(folder_path, class_name, num_labeled=20):\n",
        "    print(f'Processing class: {class_name}')\n",
        "    x_labeled, y_labeled, z_labeled = [], [], []\n",
        "    x_unlabeled, y_unlabeled, z_unlabeled = [], [], []\n",
        "\n",
        "    # Collect files and shuffle\n",
        "    file_paths = [os.path.join(folder_path, class_name, filename) for filename in os.listdir(os.path.join(folder_path, class_name))\n",
        "                  if filename.endswith(allowed_extensions)]\n",
        "    file_paths = shuffle(file_paths, random_state=42)  # Use random_state for consistency\n",
        "\n",
        "    # Split data\n",
        "    labeled_files = file_paths[:num_labeled]\n",
        "    unlabeled_files = file_paths[num_labeled:]\n",
        "\n",
        "    # Load images and assign to labeled or unlabeled\n",
        "    for file_path in labeled_files:\n",
        "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img).astype(np.uint8)\n",
        "        x_labeled.append(img_array)\n",
        "        y_labeled.append(class_mapping[class_name])\n",
        "\n",
        "    for file_path in unlabeled_files:\n",
        "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224))\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img).astype(np.uint8)\n",
        "        x_unlabeled.append(img_array)\n",
        "        y_unlabeled.append(class_mapping[class_name])\n",
        "\n",
        "    return (np.array(x_labeled), np.array(y_labeled)), (np.array(x_unlabeled), np.array(y_unlabeled))\n",
        "\n",
        "# Example usage for loading and splitting data\n",
        "folder_path = '/content/drive/My Drive/Final_Potato/train_data/archive/'\n",
        "x_labeled, y_labeled, x_unlabeled, y_unlabeled = [], [], [], []\n",
        "\n",
        "for class_name in class_mapping.keys():\n",
        "    if class_name == 'Healthy':\n",
        "        num_labeled = 90\n",
        "    else:\n",
        "        num_labeled = 20\n",
        "    (x_l, y_l), (x_u, y_u) = process_dataset_with_split(folder_path, class_name,  num_labeled)\n",
        "    plt.figure(figsize = (2,2))\n",
        "    plt.imshow(x_l[0])\n",
        "    plt.show()\n",
        "    print('#Label :', y_l.shape)\n",
        "    print('#Un Label :', y_u.shape)\n",
        "    print('====================================================')\n",
        "\n",
        "    x_labeled.append(x_l)\n",
        "    y_labeled.append(y_l)\n",
        "    x_unlabeled.append(x_u)\n",
        "    y_unlabeled.append(y_u)\n",
        "\n",
        "# Concatenate arrays from all classes\n",
        "x_labeled = np.concatenate(x_labeled, axis=0)\n",
        "y_labeled = np.concatenate(y_labeled, axis=0)\n",
        "x_unlabeled = np.concatenate(x_unlabeled, axis=0)\n",
        "y_unlabeled = np.concatenate(y_unlabeled, axis=0)\n",
        "\n",
        "print('Labeled data shape:', x_labeled.shape, y_labeled.shape)\n",
        "print('Unlabeled data shape:', x_unlabeled.shape, y_unlabeled.shape)\n"
      ],
      "metadata": {
        "id": "Ldz6zJMLbT70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_similarity.layers import MetricEmbedding\n",
        "from tensorflow_similarity.losses import CircleLoss\n",
        "from tensorflow_similarity.models import SimilarityModel\n",
        "from tensorflow_similarity.samplers import MultiShotMemorySampler\n",
        "from tensorflow_similarity.search import Searcher\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "def load_datasets():\n",
        "    # Replace with actual data loading code\n",
        "    train_data, train_labels = [], []\n",
        "    test_data, test_labels = [], []\n",
        "    return (np.array(train_data), np.array(train_labels)), (np.array(test_data), np.array(test_labels))\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = load_datasets()\n",
        "\n",
        "# Define the EfficientNet B7 model\n",
        "input_shape = (600, 600, 3)\n",
        "base_model = EfficientNetB7(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "embeddings = MetricEmbedding(512)(x)\n",
        "\n",
        "model = SimilarityModel(inputs=base_model.input, outputs=embeddings)\n",
        "model.compile(optimizer='adam', loss=CircleLoss())\n",
        "\n",
        "# Train the model\n",
        "sampler = MultiShotMemorySampler(train_images, train_labels, classes_per_batch=10, shots_per_class=10)\n",
        "history = model.fit(sampler, epochs=40, steps_per_epoch=1000, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "searcher = Searcher(model=model)\n",
        "searcher.index(train_images, train_labels)\n",
        "\n",
        "# Query an example image and get similar images\n",
        "query_image = test_images[0]\n",
        "query_label = test_labels[0]\n",
        "similar_images, similar_labels, distances = searcher.search(query_image, k=20)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Query image label: {query_label}\")\n",
        "print(f\"Top 20 similar images and their distances: {list(zip(similar_labels, distances))}\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "y_true = [query_label] * len(similar_labels)\n",
        "y_pred = similar_labels\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Visualize the results\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(5, 5, 1)\n",
        "plt.imshow(query_image)\n",
        "plt.title(f\"Query: {query_label}\")\n",
        "plt.axis('off')\n",
        "\n",
        "for i, (image, label, distance) in enumerate(zip(similar_images, similar_labels, distances)):\n",
        "    plt.subplot(5, 5, i+2)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Label: {label}, Dist: {distance:.2f}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "502Q6XCDb1eH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}